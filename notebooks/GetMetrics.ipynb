{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04f8bbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pickle as pkl\n",
    "import trimesh\n",
    "import numpy as np\n",
    "\n",
    "from pixtrack.utils.pose_utils import geodesic_distance_for_rotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fed1190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pose_mat_from_tensor(pose_tensor):\n",
    "    translation = pose_tensor.t.cpu().numpy()\n",
    "    rotation = pose_tensor.R.cpu().numpy()\n",
    "    mesh_pose_in_cam = np.eye(4)\n",
    "    mesh_pose_in_cam[:3, :3] = rotation\n",
    "    mesh_pose_in_cam[:3, -1] = translation\n",
    "    return mesh_pose_in_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca4f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_transform(from_points, to_points):\n",
    "    \n",
    "    assert len(from_points.shape) == 2, \\\n",
    "        \"from_points must be a m x n array\"\n",
    "    assert from_points.shape == to_points.shape, \\\n",
    "        \"from_points and to_points must have the same shape\"\n",
    "    \n",
    "    N, m = from_points.shape\n",
    "    \n",
    "    mean_from = from_points.mean(axis = 0)\n",
    "    mean_to = to_points.mean(axis = 0)\n",
    "    \n",
    "    delta_from = from_points - mean_from # N x m\n",
    "    delta_to = to_points - mean_to       # N x m\n",
    "    \n",
    "    sigma_from = (delta_from * delta_from).sum(axis = 1).mean()\n",
    "    sigma_to = (delta_to * delta_to).sum(axis = 1).mean()\n",
    "    \n",
    "    cov_matrix = delta_to.T.dot(delta_from) / N\n",
    "    \n",
    "    U, d, V_t = np.linalg.svd(cov_matrix, full_matrices = True)\n",
    "    cov_rank = np.linalg.matrix_rank(cov_matrix)\n",
    "    S = np.eye(m)\n",
    "    \n",
    "    if cov_rank >= m - 1 and np.linalg.det(cov_matrix) < 0:\n",
    "        S[m-1, m-1] = -1\n",
    "    elif cov_rank < m-1:\n",
    "        raise ValueError(\"colinearility detected in covariance matrix:\\n{}\".format(cov_matrix))\n",
    "    \n",
    "    R = U.dot(S).dot(V_t)\n",
    "    c = (d * S.diagonal()).sum() / sigma_from\n",
    "    t = mean_to - c*R.dot(mean_from)\n",
    "    \n",
    "    return R, c, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c1cf7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pose_offset(poses_file):\n",
    "    from_trs = []\n",
    "    to_trs = []\n",
    "    for image_key in poses_file:\n",
    "        if (not poses_file[image_key][\"success\"]):\n",
    "            continue\n",
    "        to_trs.append(poses_file[image_key][\"T_refined\"].t.cpu().numpy())\n",
    "        from_trs.append(poses_file[image_key][\"gt_pose\"].t.cpu().numpy())\n",
    "    R, c, t = similarity_transform(np.array(from_trs), np.array(to_trs))\n",
    "    pose_from_res_to_gt = np.eye(4)\n",
    "    pose_from_res_to_gt[:3, :3] = R\n",
    "    pose_from_res_to_gt[:3, -1] = t\n",
    "    return pose_from_res_to_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0616f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "from pytorch3d.loss import chamfer_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6e2dd642",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_path = \"/mnt/remote/data/prajwal/YCB_Video_Dataset/models/035_power_drill/textured.obj\"\n",
    "\n",
    "object_mesh = trimesh.load(mesh_path)\n",
    "vertices = np.array(object_mesh.vertices)\n",
    "vertices = np.hstack((vertices, np.ones((vertices.shape[0], 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "cee38200",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder = \"/mnt/remote/data/prajwal/pixtrack/results/021_bleach_cleanser/\"\n",
    "poses_file = os.path.join(result_folder, \"poses.pkl\")\n",
    "with open(poses_file, \"rb\") as f:\n",
    "    poses_file = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "044b967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(poses_file, tr_threshold, rot_threshold):\n",
    "    distances = []\n",
    "    add_ss = []\n",
    "    pose_dists = []\n",
    "\n",
    "    pose_from_res_to_gt = get_pose_offset(poses_file)\n",
    "    bad_count = 0\n",
    "\n",
    "    for image_key in poses_file:\n",
    "        if (not poses_file[image_key][\"success\"]):\n",
    "            #print(f\"skipped {image_key}\")\n",
    "            continue\n",
    "        res_pose_mat = get_pose_mat_from_tensor(poses_file[image_key][\"T_refined\"])\n",
    "        gt_pose_mat = get_pose_mat_from_tensor(poses_file[image_key][\"gt_pose\"])\n",
    "        aligned_res_pose = np.dot(pose_from_res_to_gt, res_pose_mat)\n",
    "        tr_dist = np.linalg.norm(gt_pose_mat[:3, -1] - aligned_res_pose[:3, -1]) * 100\n",
    "        rot_dist = geodesic_distance_for_rotations(gt_pose_mat[:3, :3], aligned_res_pose[:3, :3]) * 180 / np.pi\n",
    "        res_vertices = np.dot(pose_from_res_to_gt, np.dot(res_pose_mat, vertices.T)).T[:, :3] * 100\n",
    "        gt_vertices = np.dot(gt_pose_mat, vertices.T).T[:, :3] * 100\n",
    "\n",
    "\n",
    "        l2_distances = np.linalg.norm(gt_vertices - res_vertices, axis=1)\n",
    "        pose_dists.append(tr_dist)\n",
    "        l2_dist = np.mean(l2_distances)\n",
    "        if tr_dist > tr_threshold or rot_dist > rot_threshold:\n",
    "            bad_count += 1\n",
    "            \n",
    "        distances.append(l2_dist)\n",
    "        \n",
    "        \n",
    "    results = {}\n",
    "    results[\"average_error_vertices\"] = np.mean(distances)\n",
    "    results[\"max_error\"] = np.max(distances)\n",
    "    results[\"max_translation_error\"] = np.max(pose_dists)\n",
    "    results[\"average_translation_error_pose\"] = np.mean(pose_dists)\n",
    "    results[\"bad_count\"] = bad_count\n",
    "    results[\"total_frames\"] = len(poses_file)\n",
    "    results[\"accuracy\"] = (1.0*(len(poses_file) - bad_count))/(1.0*len(poses_file) )\n",
    "    return results\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1981d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = get_metrics(poses_file, tr_threshold=5, rot_threshold=5)\n",
    "res2 = get_metrics(poses_file, tr_threshold=3, rot_threshold=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "af7c1c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh_1: {'average_error_vertices': 1.3623460859796348, 'max_error': 8.831234976584756, 'max_translation_error': 8.82980144481684, 'average_translation_error_pose': 1.3492508181637395, 'bad_count': 3, 'total_frames': 1590, 'accuracy': 0.9981132075471698} \n",
      " thresh_2:{'average_error_vertices': 1.3623460859796348, 'max_error': 8.831234976584756, 'max_translation_error': 8.82980144481684, 'average_translation_error_pose': 1.3492508181637395, 'bad_count': 164, 'total_frames': 1590, 'accuracy': 0.8968553459119497}\n"
     ]
    }
   ],
   "source": [
    "print(f\"thresh_1: {res1} \\n thresh_2:{res2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80cecdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "11b1a286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.749795552275344"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2.909139344971845 + 9.88552130601735 + 2.504790297611688 + 3.699731260500495)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bfc9997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /mnt/remote/data/prajwal/pixtrack/results/021_bleach_cleanser/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cec9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
